[<div class="jobdescription-item">
                            job summary:<br/>  Our Major Financial Client is seeking a Python Developer Professional .<br/><br/>   Technical Must Haves: Python - Restful APIs, ETL - Python packages of most interest - Pandas &amp; Request package, Pyodbc, and SQL Alchemy. Other key skills are GIT, Jenkins, Gradle. Automation wise Cucumber or Fitness or Selenium. Kubernetes and Docker would also be preferred. Must have CI/CD experience. Must have experience supporting an Agile environment. Must have SQL database experience.<br/><br/> Any AWS experience is preferred but not required.<br/><br/>   Requirements:<br/><br/> - Bachelor's degree in Computer Science, Engineering, Data Analytics/Data Science or equivalent working experience<br/><br/> - 2+ years of Data Engineering experience using AWS (RDS, Kinesis, S3, Glue, Athena, EMR, Data lake, Snowflake) and Data Governance Solutions (Collibra and Talend)<br/><br/> - 2+ years' experience in agile development environment including: Dev Ops, CI/CD, Gradle, Spinnaker, Bitbucket, GIT, Kubernetes, Docker, Jenkins)<br/><br/> - 2+ years' experience in automated test frameworks (Fitnesse, Selenium, Cucumber)<br/><br/> - 2+ years' experience in Python<br/><br/> - 2+ years of software development experience<br/><br/>     <br/>  location: Mc Lean, Virginia<br/>  job type: Contract<br/>  salary: $40.00 - 43.75 per hour<br/>  work hours: 8am to 5pm<br/>  education: Bachelors<br/>   <br/>  responsibilities:<br/>  - Responsible for delivery in the areas of data engineering including technology implementations<br/><br/>    - Develop scalable and reliable data solutions to move data across systems from multiple sources in real time as well as batch modes<br/><br/>    - Construct data staging layers and fast real-time systems<br/><br/>    - Utilize expertise in models that leverage the newest data sources, technologies, and tools, such as machine learning, Python, Hadoop, Spark, AWS, as well as other cutting-edge tools and applications for Big Data<br/><br/>    - Investigate the impact of new technologies, applications, and data sources to business areas supported<br/><br/>    - Quickly learn new tools and paradigms to deploy cutting edge solutions<br/><br/>    - Develop both deployment architecture and scripts for automated system deployment in AWS<br/><br/>    - Create large scale deployments using newly researched methodologies<br/><br/>    - Work in Agile environment<br/><br/>        <br/>  qualifications:<br/> <ul> <li>Experience level: </li><li>Minimum 3 years of experience</li><li>Education: Bachelors</li></ul> <br/>  skills: <ul><li>Python</li></ul><br/>    Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.<br/><br/>
</div>]